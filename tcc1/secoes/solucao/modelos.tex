%!TEX root = ../../main.tex

Como visto anteriormente, arquiteturas eficientes de CNNs que satisfaçam as necessidades encontradas em determinada tarefa de aprendizado ainda são difíceis de se elaborar. Consequentemente, para o problema apresentado neste trabalho, escolheu-se utilizar topologias canônicas de CNNs, ajustando seus parâmetros e hiperparâmetros com a finalidade de encontrar modelos que possuam um bom desempenho para a tarefa de aprendizado aqui definida.

Os parâmetros estão relacionados aos pesos atribuídos a uma rede neural, enquanto os hiperparâmetros estão relacionados ao ajuste em nível de arquitetura das CNNs \cite{chollet}\todo{Parei aqui, refazer última sentença utilizando o chollet}.

% \begin{table}[h!]
% 	\centering
% 	\caption{Parâmetros e hiperparâmetros selecionados para o treinamento dos modelos propostos.}
% 	\label{tab:parametros}
% 	\begin{tabular}{c c c c c}
% 		\toprule
% 		 \textbf{CNN} & \textbf{Épocas} & \textbf{\emph{Patience}} & \textbf{Otimizador} & \textbf{Função de ativação}  \\
% 		\midrule
% 		AlexNet & 200 & 20 & SGD & ReLU \\
%     LeNet & 200 & 20 & Adam & Leaky ReLU \\
% 		\bottomrule
% 	\end{tabular}
% \end{table}
