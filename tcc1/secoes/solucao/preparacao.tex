%!TEX root = ../../main.tex

Sabe-se que algoritmos de AM necessitam de quantidade significantiva de dados, preferencialmente sem muitos ruídos, para serem utilizados de forma a obter um modelo que possua bom desempenho \cite{marsland}. Levando isto em conta e com vistas a adequar os dados disponíveis com a tarefa de aprendizado considerada, uma etapa de pré-processamento fez-se necessária, cujos passos são descritos a seguir.

Primeiramente foi necessário realizar a adaptação das imagens individuais para as imagens compostas, conforme apresentado anteriormente no esquema da Figura \ref{fig:esquema-solucao}. Para isto, foi feita a combinação de cada assinatura genuína de um autor com suas diferentes versões originais, produzindo uma nova imagem para cada caso, a qual associou-se o rótulo de autêntica. Após esta etapa, também foram combinados os exemplos genuínos com suas respectivas versões forjadas, aos quais foi associado o rótulo de forjado. Todas as imagens obtidas dessas combinações serão utilizadas como exemplos para o processo de treinamento, validação e teste do modelo proposto.

Para preservar a referência aos autores e ids de suas assinaturas, os nomes dos arquivos passaram a conter tais informações. Entretanto, ressalta-se que os modelos de CNNs não terão acesso a este dado (nome do arquivo). Ele serve de referência apenas para verificar a procedência do exemplo.

O processo de combinação das imagens de cada um dos exemplos foi realizado em três etapas. Na primeira etapa, ambas as imagens foram redimensionadas para um tamanho de $256 \times 256$ \emph{pixels}. Em seguida, as imagens foram concatenadas verticalmente com a intenção de formar uma única imagem de $256 \times 512$ \emph{pixels}. Por fim, a imagem resultante foi redimensionada novamente em um tamanho de $256 \times 256$ \emph{pixels} e transformada para um espaço de cores em escala de cinza, com a intenção de padronizar todos os exemplos.

Ao concluir a etapa anterior, realizou-se então, nos exemplos autênticos, a partição \emph{holdout} previamente especificada. Porém, esta mesma ideia não podia ser realizada nos exemplos forjados, pois culminaria na apresentação de uma mesma falsificação na etapa de treinamento e de teste, favorecendo a sua detecção. Em um cenário prático de eventual utilização da solução proposta, o modelo construído já terá sido treinado e será requisitado a avaliar uma assinatura potencialmente forjada, mas nunca antes vista. Levando isto em consideração, a etapa de testes apenas incluirá assinaturas forjadas inéditas para o modelo. Para que isso fosse possível, alguns critérios de separação foram adotados:

\begin{itemize}
	\item Se uma assinatura autêntica possui apenas um autor forjador, todos os exemplos forjados serão incluídos no conjunto de treinamento;
	\item Se uma assinatura autêntica possui quatro autores forjadores, as assinaturas de três desses autores irão para o conjunto de treinamento e as remanescentes, pertencentes a apenas um autor, irão para o conjunto de teste;
	\item Se uma assinatura autêntica possui cinco autores forjadores, as assinaturas de quatro desses autores irão para a etapa de treinamento e as remanescentes, pertencentes a apenas um autor, estarão presentes na etapa de teste;
	\item Se uma assinatura autêntica possui seis autores forjadores, as assinaturas de quatro desses autores irão para a etapa de treinamento e as assinaturas dos outros dois irão para a etapa de teste;
	\item Se uma assinatura possui trinta ou mais autores forjadores, as assinaturas de dez desses autores irão para o conjunto de teste, três desses autores serão utilizados para o conjunto de validação e as assinaturas restantes serão remanejadas para o conjunto de treinamento.
\end{itemize}

Os autores forjadores selecionados para estarem presentes em cada uma das partições foram escolhidos de forma pseudoaleatória. Dessa maneira, ressalta-se que os conjuntos de treino, teste e validação são disjuntos no tocante aos autores forjadores.

Após o particionamento dos dados conforme especificado, tem-se o quantitativo dos dados de treino, validação e teste dispostos conforme Tabela \ref{tab:divisao-dados} e com proporcionalidades apresentadas na Figura \ref{fig:divisao-dados}. Percebe-se que há uma certa desproporção entre as classes nas etapas de treino e validação. Na etapa de testes, esta diferença torna-se mais evidente e será refletida nas métricas de desempenho dos modelos.

\begin{table}[h!]
	\centering
	\caption{Quantitativo de exemplos por finalidade na tarefa de aprendizado considerada e classe.}
	\label{tab:divisao-dados}
	\begin{tabular}{c c c c}
		\toprule
		\textbf{Conjunto} & \textbf{Tipo de Exemplo} & \textbf{Quantidade de Dados} & \textbf{Proporção}\\
		\midrule
		\multirow{2}{*}{Treinamento} & Autêntico & 9.374 & $54\%$ \\
    & Forjado & 8.131 & $46\%$\\
     \midrule
		 \multirow{2}{*}{Validação} & Autêntico & 947 & $46\%$ \\
     & Forjado & 1.134 & $54\%$\\
		 \midrule
		 \multirow{2}{*}{Teste} & Autêntico & 2.257 & $27\%$ \\
     & Forjado & 6.119 & $73\%$\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{figure}[h!]
\centering
\caption{Representação gráfica da proporção dos exemplos por classe e finalidade na tarefa de aprendizado considerada.}
\label{fig:divisao-dados}
\includegraphics[width=0.6\textwidth]{imgs/divisao-dados}
\end{figure}

Ao serem fornecidas para treinamento pelas CNNs em etapa posterior, todos os \emph{pixels} das imagens serão normalizados por meio de uma divisão por $255$, passando a residirem no intervalo $[0,1]$. Esta normalização é realizada em virtude das redes neurais que, em geral, aprendem mais eficientemente nestas condições \cite{chollet}.
