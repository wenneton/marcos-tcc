%!TEX root = ../../main.tex

As tecnologias utilizadas para a realização desse trabalho são, em sua maior parte, relacionadas à linguagem de programação \emph{Python}. A escolha dessa linguagem se dá pela sua popularidade para fins de criação de modelos de ML, assim como a grande quantidade de bibliotecas que facilitam o desenvolvimento desses modelos.

Para o pré-processamento das imagens em termos de redimensionamento e criação dos exemplos dispostos aos modelos, utilizou-se a biblioteca \texttt{PIL} (Pillow) \cite{pillow}. Quanto à manipulação e organização dos arquivos, foram utilizadas as bibliotecas \texttt{os} e \texttt{glob} \cite{os,glob}. A aplicação do treinamento e teste dos modelos propostos ficou por conta das bibliotecas \texttt{keras} e \texttt{tensorflow}\cite{keras, tensorflow}. No que diz respeito ao cálculo de métricas de desempenho, as bibliotecas que tiveram um papel protagonista foram a \texttt{scikit-learn} e a \texttt{numpy}, na qual a última também teve a responsabilidade de manipular o conjunto de imagens e as suas representações matriciais \cite{sklearn,numpy}. Por fim, a visualização dos dados de treinamento e de alguns resultados ficou por conta de biblioteca \texttt{matplotlib} \cite{matplotlib}.

Sabe-se que o treinamento de uma CNN requer um custo computacional muitas vezes não alcançado por unidades de processamento comuns. Portanto, com a finalidade de treinar os modelos propostos, foram utilizadas as GPUs disponíveis no Laboratório de Sistemas Inteligentes da UEA. Porém, durante algumas fases do treinamento das redes, a utilização dos \emph{Kernels} da plataforma \emph{Kaggle} também foram de grande ajuda. Esse recurso permite a utilização de ambientes que facilitam a reprodução de trabalhos relacionados a ciência de dados, possuindo uma grande quantidade de pacotes pré-instalados e a customização de recursos computacionais como GPUs e outros \cite{kaggle}.
